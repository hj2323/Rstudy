filter(flights, Month==1, DayofMonth==1)
flights=flgihts
filter(flights, Month==1, DayofMonth==1)
filter(flights, UniqueCarrier=="AA" | UniqueCarrier=="UA")
select(flights, DepTime, ArrTime, FlightNum)
select(flights, Year:DayofMonth, contains("Taxi"), contains("Delay"))
na2 = flights %>%
select(UniqueCarrier, DepDelay) %>%
filter(DepDelay > 60)
na2
> flights %>%
select(UniqueCarrier, DepDelay) %>%
arrange(DepDelay)
flights %>%
select(UniqueCarrier, DepDelay) %>%
arrange(desc(DepDelay))
flights %>%
select(UniqueCarrier, DepDelay) %>%
arrange(DepDelay)
> flights %>%
select(Distance, AirTime) %>%
mutate(Speed = Distance/AirTime*60)
flights %>%
select(Distance, AirTime) %>%
mutate(Speed = Distance/AirTime*60)
flights %>%
group_by(Dest) %>%
summarise(avg_delay = mean(ArrDelay, na.rm=TRUE))
flights %>%
group_by(UniqueCarrier) %>%
summarise_each(funs(mean), Cancelled, Diverted)
data <- 1:10
data
market = read.table("c:/data/reg/market-1.txt", header=T)
head(market)
plot(market$X, market$Y, xlab="광고료", ylab="총판매액", pch=19)
title("광고료와 판매액의 산점도")
market.lm = lm(Y~X, data=market)
summary(market)
plot(market$X, market$Y, xlab="광고료", ylab="총판매액", pch=19)
abline(market.lm)
identify(market$X, market$Y)
names(market.lm)
resid=market.lm$residuals
fitted=market.lm$fitted
sum(resid)
sum(fitted)
sum(market$X*resid)
sum(fitted*resid)
#점 x bar , y bar는 적합된 회귀선상에 있음
xbar = mean(market$X)
ybar = mean(market$Y)
xbar
ybar
points(xbar, ybar, pch=17, cex=2.0, col="RED")
text(xbar, ybar, "(8.85, 19.36)")
fx<- "Y-hat = 0.328+2.14*X"
text(locator(1), fx)
#locator(1): 임의의 마우스 위치에
anova(market.lm)
### 2-6
score<-c(93, 83, 91, 68, 75, 87, 89, 96, 97, 67, 83, 81, 87, 80, 64,
83, 88, 76, 91, 78, 72, 80, 69, 80, 84, 71, 91, 81, 88, 73)
hist(score)
hist(score, main="")
### 2-7
rv<-c(0.8, 0.8, 0.8,  0.9, 0.9, 0.9, 0.9, 0.9, 1, 1, 1.8, 2, 2.1, 2.3, 2.4, 2.8,
2.9, 3, 3.2, 3.3, 3.5, 3.8, 3.8, 3.9, 4, 4.2, 4.4, 4.5, 5.1, 5.3, 5.3, 5.4,
14, 17, 18, 19, 21, 21, 23, 25, 27, 28, 32, 34, 36, 41, 42, 44, 48, 49,
51, 54, 59, 60, 61, 62, 80, 240)
hist(rv)
hist(rv, main="", xlab="CRP")
hist(rv, main="", xlab="CRP", breaks = 20)
hist(rv, main="", xlab="CRP", breaks = seq(0, 240, 20))
rn<-c(rnorm(100,5,2), rnorm(100,10,2))
set.seed(2021)
rn<-c(rnorm(100,5,2), rnorm(100,10,2))
hist(rn)
hist(rn, breaks=20, main="", xlab="value")
hist(rn, breaks=5, main="", xlab="value")
# 2-15
age<-c(57, 61, 47, 57, 48, 58, 57, 61, 54, 50, 68, 51)
boxplot(age)
boxplot(age, ylab="Age")
#2-16
member<-c(92, 107, 180, 90, 78, 91, 102, 88, 106, 125, 95, 102, 162)
boxplot(member)
boxplot(member, ylab="Number of board member")
member<-c(92, 107, 180, 90, 78, 91, 102, 88, 106, 125, 95, 102, 162)
mean(member)
var(member)
sd(member)
median(member)
fivenum(member)
IQR(member)
range(member)
###1. 분산분석표에 의한 F-검정
#window
market2 = read.table('C:\data\reg/market-2.txt', header=T)
head(market2, 2)
###1. 분산분석표에 의한 F-검정
#window
market2 = read.table('C:/data/reg/market-2.txt', header=T)
head(market2, 2)
market2.lm = lm(Y~X1+X2, data=market2)
summary(market2.lm)
names(market2.lm)
yhat=market2.lm$fited
cor(market2$Y, yhat)
yhat=market2.lm$fitted
cor(market2$Y, yhat)
cor(market2$Y, yhat)^2
#수정결정계수Adjusted R-squared
#잔차평균제곱근Residual standard error
sqrt(10.42/12)
print(Hello MuiltivariateDataAnalysis!)
survey = read.csv("c:/data/mva/survey.csvc")
survey = read.csv("c:/data/mva/survey.csv")
head(survey,3)
mean(survey$age)
sd(survey$age)
nlevels(survry$sex)
nlevels(survey$sex)
survey$sex = factor(survey$sex, levels=c(1:2), labels=c("Male", "Female"))
nlevels(survey$sex)
summary(survey[,-1])
###그룹별 기술통계량 구하기
tapply(survey$age, survey$sex, mean)
with(survey, tapply(age, sex, sd))
###두개의 변수 연결
sex_ma = list(survey$sex, survey$marriage)
table(sex_ma)
with(survey, tapply(age, sex_ma, mean))
with(survey, tapply(age, sex_ma, sd))
####################################################
### 주성분 분석(principal component analysis)
####################################################
# 1. 자료 가져오기
data("USArrests")
head(USArrests)
summary(USArrests)
boxplot(USArrsts)
boxplot(USArrests)
write.csv(USArrests, file='C:/data/mva/USArrests.csv')
# 2. 주성분 분석 실행
usarr_pca = princomp(USArrests, cor=T, scores=T)
names(usarr_pca)
usarr_pca
# 3. 주성분 분석 결과
summary(usarr_pca)
eig_val = usarr_pca$sdev^2
round(eig_val, 3)
# 5. 스크리그림과 누적분산
# 스크리그림
screeplot(usarr_pca, type="lines", pch=19, main="Scree plot")
# 누적분산 그림 그리기
usarr_var = usarr_pca$sdev^2
usarr_var_ratio = usarr_var/sum(usarr_var)
round(usarr_var_ratio, 3)
plot(cumsum(usarr_var_ratio), type='b', pch=19, xlab='Component',
ylab='Cumulative Proporton')
title('Variance Explained')
plot(cumsum(usarr_var_ratio), type='a', pch=19, xlab='Component',
ylab='Cumulative Proporton')
plot(cumsum(usarr_var_ratio), type='b', pch=19, xlab='Component',
ylab='Cumulative Proporton')
plot(cumsum(usarr_var_ratio), type='i', pch=19, xlab='Component',
ylab='Cumulative Proporton')
plot(cumsum(usarr_var_ratio), type='b', pch=19, xlab='Component',
ylab='Cumulative Proporton')
# 6. 주성분 계수
round(usarr_pca$loadings[,c(1:2)], 3)
# 7. 주성분 점수 및 행렬도(biplot)
usarr_pca$scores[, c(1:2)]
biplot(usarr_pca, cex=0.7, col=c("Red", "Blue"))
title("Biplot")
# 7. 주성분 점수 및 행렬도(biplot)
usarr_pca$scores[c(1:7), c(1:2)]
biplot(usarr_pca, cex=0.7, col=c("Red", "Blue"))
title("Biplot")
####################################################
### 주성분 분석(principal component analysis)
####################################################
# 1. 자료 가져오기
data("USArrests")
head(USArrests)
summary(USArrests)
boxplot(USArrests)
# 2. 주성분 분석 실행
# Principal component analysis using prcomp (using SVD)
usarr_pca =  prcomp(USArrests, scale=TRUE)
names(usarr_pca)
usarr_pca
# 3. 주성분 분석 결과
summary(usarr_pca)
eig_val = usarr_pca$sdev^2
eig_val = usarr_pca$sdev^2
round(eig_val, 3)
# 5. 스크리그림과 누적분산
# 스크리그림
screeplot(usarr_pca, type="lines", pch=19, main="Scree plot")
# 누적분산 그림 그리기
usarr_var = usarr_pca$sdev^2
usarr_var_ratio = usarr_var/sum(usarr_var)
round(usarr_var_ratio, 3)
plot(cumsum(usarr_var_ratio), type='b', pch=19, xlab='Component',
ylab='Cumulative Proporton')
title('Variance Explained')
# 6. 주성분 계수
round(usarr_pca$rotation[, c(1:2)], 3)
anscombe
obj1<-lm(y1~x1, data=anscombe)
round(obj$coefficients,1)
round(obj1$coefficients,1)
##################################
### EDA
##################################
### pie chart
set.seed(2022)
df <- data.frame(blood_type = sample(c('A', 'B', 'AB', 'O'), replace = TRUE, size = 100))
df
blood_type = sample(c('A', 'B', 'AB', 'O'), replace = TRUE, size = 100))
sort.df = sort(table(df), decreasing = T)
sort.df
par(mfrow = c(1,2))
slices = c("red", "blue", "yellow", "green")
par(mfrow = c(1,2))
slices = c("red", "blue", "yellow", "green")
pie(sort.df, col=slices, radius=1, main="원그래프")
# election
require(grDevices)
pie.vote <- c(0.5067, 0.0167, 0.0100, 0.0433, 0.4233)
pie(pie.vote)
# election
require(grDevices)
pie.vote <- c(0.5067, 0.0167, 0.0100, 0.0433, 0.4233)
names(pie.vote) <- c("새누리 152명", "선진 5명","무 3명",
"진보 13명","민주 127명", )
names(pie.vote) <- c("새누리 152명", "선진 5명","무 3명",
"진보 13명","민주 127명")
pie(pie.vote)
par(mfrow = c(1,1))
pie.vote <- c(0.5067, 0.0167, 0.0100, 0.0433, 0.4233)
names(pie.vote) <- c("새누리 152명", "선진 5명","무 3명",
"진보 13명","민주 127명")
pie(pie.vote)
pie(pie.vote, col=c("red3", "blue", "green3", "magenta", "yellow"),
main = "19대 국회의원 선거")
# 원띠그래프
par(new=T)
pie(c(152, 127, 13, 5, 3), radius = 0.8, col="white", label=NA, border=NA)
text(0,0, "총 300석")
pie(c(152, 127, 13, 5, 3), radius = 1.2ㅋ, col="white", label=NA, border=NA)
pie(c(152, 127, 13, 5, 3), radius = 1.2, col="white", label=NA, border=NA)
pie(c(152, 127, 13, 5, 3), radius = 0.5, col="white", label=NA, border=NA)
# 원띠그래프
par(new=T)
pie(c(152, 127, 13, 5, 3), radius = 0.5, col="white", label=NA, border=NA)
text(0,0, "총 300석")
pie(c(152, 127, 13, 5, 3), radius = 0.8, col="white", label=NA, border=NA)
### barplot
barplot(sort.df, col=slice, main="막대그래프")
### barplot
barplot(sort.df, col=slices, main="막대그래프")
# election
require(grDevices)
pie.vote <- c(0.5067, 0.0167, 0.0100, 0.0433, 0.4233)
names(pie.vote) <- c("새누리 152명", "선진 5명","무 3명",
"진보 13명","민주 127명")
barplot(pie.vote, col=c("red3", "blue", "green3", "magenta", "yellow"), main="막대그래프")
### hist
# 외부파일을 읽어 데이터프레임을 만들기
담즙과포화비율 = read.table("C:\chj\Rstudy\dataviz\담즙과포화비율-자료.txt", header=T)
### hist
# 외부파일을 읽어 데이터프레임을 만들기
담즙과포화비율 = read.table("C:\\chj\\Rstudy\\dataviz\\담즙과포화비율-자료.txt", header=T)
### hist
# 외부파일을 읽어 데이터프레임을 만들기
담즙과포화비율 = read.table("C:\\chj\\Rstudy\\dataviz\\담즙과포화비율.txt", header=T)
### hist
# 외부파일을 읽어 데이터프레임을 만들기
담즙과포화비율 = read.table("C:\\chj\\Rstudy\\dataviz\\담즙과포화비율.txt", header=T)
attach(담즙과포화비율)
str(담즙과포화비율)
# 자료를 읽어 산점도 그리기
forbes = read.table("c:/data/reg/forbes.txt")
# 자료를 읽어 산점도 그리기
forbes = read.table("c:/data/reg/forbes.txt")
head(forbes, 3)
# 자료를 읽어 산점도 그리기
forbes = read.table("c:/data/reg/forbes.txt", header=T)
head(forbes, 3)
attach(forbes)
Lpress = 100 * log(10(press), base=10)
Lpress = 100 * log(10*press, base=10)
Lpress
plot(temp, Lpress, pch=19)
# 회귀모형 적합하기
forbes.lm = lm(Lpress ~ temp, data=forbes)
summary(forbes.lm)
# 분산분석표 구하기
anova(forbes.lm)
# 잔차 및 추정값 보기
names(forbes.lm)
cbind(forbes, forbes.lm$residuals, forbes.lm$fitted.values)
# 잔차 그림 그리기
plot(temp, forbes.lm$residuals, pch=19)
abline(h=0, lty=2)
# 추정값의 신뢰대 그리기
p.x = data.frame(temp=c(1, 45))
pc=predict(forbes.lm, int="c", newdata=p.x)
pred.x = p.x$temp
plot(temp, Lpress, ylim = range(Lpress, pc))
matlines(pred.x, pc, lty=c(1,2,2), col="BLUE")
# 자료를 읽어 산점도 그리기
achiv = read.table("C:\\data\\R_IntroStat\\achievement.txt", header=T)
head(achiv, 3)
attach(achiv)
plot(after, before, pch=19)
# 회귀모형 적합하기
achiv.lm = lm(before ~ after, data=achiv)
summary(achiv.lm)
plot(before, after, pch=19, xlab='방과후 학습 전 성취도',
ylab='방과후 학습 후 성취도')
abline(achiv.lm)
### 히스토그램 그리기
numberofbook <- c(8,1,10,15,15,10,5,19,20,9,10)
hist(numberofbook, main="")
### 다섯수치요약 산출
fivenum(numberofbook)
### 상자그림 그리기
boxplot(numberofbook, ylab="학생 11명의 1년 동안 읽은 책 수")
hist(numberofbook, main="")
### 상자그림 그리기
boxplot(numberofbook, ylab="학생 11명의 1년 동안 읽은 책 수")
# 데이터 입력
score = c(88,83,83,85,94,88,91,96,89,83,81,80,84,89,83,79)
# 표본평균과 표본표준편차
bar_x = mean(score)
s = sd(score)
n = length(score)
# 모평균의 95% 신뢰구간
qt(0.975, 15)
qt(0.025, 15, lower.tail = FALSE)
c(bar_x - qt_95*s/sqrt(n), bar_x + qt_95*s/sqrt(n))
qt_95 = qt(0.975, 15)
c(bar_x - qt_95*s/sqrt(n), bar_x + qt_95*s/sqrt(n))
t.test(score)$conf.int
c(p_hat-z_1*sqrt(p_hat*(1-p_hat/n), p_hat+z_1*sqrt(p_hat*(1-p_hat)/n))
c(p_hat-z_1*sqrt(p_hat*(1-p_hat/n), p_hat+z_1*sqrt(p_hat*(1-p_hat)/n)))
c(p_hat-z_1*sqrt(p_hat*(1-p_hat)/n), p_hat+z_1*sqrt(p_hat*(1-p_hat)/n))
# 모비율의 신뢰구간
n = 500
X = 200
p_hat = X/n
alpha = 0.05
z_1 = qnorm(1-alpha/2)
c(p_hat-z_1*sqrt(p_hat*(1-p_hat)/n), p_hat+z_1*sqrt(p_hat*(1-p_hat)/n))
prop.test(X, n)$conf.int
q_2 = qchisq(alpha/2, n-1)
q_1 = qchisq(1-alpha/2, n-1)
# 모분산의 신뢰구간
s2 = 4^2
n=40
alpha = 0.05
c((n-1)*s2/q_1, (n-1)*s2/q_2)
install.packages("vcd")
library(vcd)
data <- Arthritis
head(data)
summary(data)
# plot() 사용 그리기
par(mfrow=c(1,2))
# 모자이크 플롯 그리기
mosaicplot(~ Treatment+Improved, data=Arthritis, color=c("grey", "blue"))
mosaicplot(~ Sex+Improved, data=Arthritis, color=c("grey", "blue"))
### 3. 뉴욕의 대기질에 관한 데이터셋,
airquality
head(airquality)
summary(airquality)
# 산점도 행렬 그리기
data(airquality)
attach(airquality)
pairs(airquality[1:4], main="AirQuality")
### 3. 뉴욕의 대기질에 관한 데이터셋,
iris
# 산점도 행렬 그리기
data(airquality)
# 산점도 행렬 그리기
airquality
pairs(airquality[1:4], main="AirQuality", pch=21, bg=c("#FF0000","#FF0000","#00FF00","#00FFFF","#0000FF","#FF00FF")[unclass(airquality$Month )])
pairs(airquality[1:4], main="AirQuality", pch=21, bg=c("red","yellow","green","cyan","blue","magenta")[unclass(airquality$Month )])
pairs(airquality[1:4], main="AirQuality", pch=21, bg=c("red","yellow","green","cyan","blue","magenta")[unclass(airquality$Month)])
# 산점도 행렬 그리기
airquality
data(airquality)
attach(airquality)
pairs(airquality[1:4], main="AirQuality")
pairs(airquality[1:4], main="AirQuality", pch=21, bg=c("red","yellow","green","cyan","blue","magenta")[unclass(airquality$Month)])
pairs(airquality[1:4], main="AirQuality")
pairs(airquality[1:4], main="AirQuality", pch=21,
bg=c("red","yellow","green","cyan","blue","magenta")[unclass(airquality$Month)])
bg=c("red","yellow","green","cyan","blue)[unclass(airquality$Month)])
pairs(airquality[1:4], main="AirQuality", pch=21,
bg=c("red","yellow","green","cyan","blue")[unclass(airquality$Month)])
pairs(airquality[1:4], main="AirQuality", pch=21,
bg=c("red","yellow","green","cyan","blue")[unclass(airquality$Month)])
pairs(airquality[1:4], main="AirQuality", pch=21,
bg=c("red","yellow","green","cyan")[unclass(airquality$Month)])
pairs(airquality[1:4], main="AirQuality", pch=21,
bg=c("red","yellow","green","cyan","blue")[unclass(airquality$Month)])
install.packages("neuralnet")
install.packages("neuralnet")
library(neuralnet)
set.seed(130)
ind1=1:100
ind2=ind1/100
cos2=cos(ind2*4*pi)
cdat=data.frame(cbind(ind2, cos2))
cos2.nn=neuralnet(cos2~ind2, data=cdat, hidden=5, linear.output=T)
plot(cos2.nn)
cos.pred = predict(cos2.nn, data.frame(ind2))
plot(ind1, cos.pred)
lines(cos2)
cos2.nn=neuralnet(cos2~ind2, data=cdat, hidden=5, linear.output=T)
plot(cos2.nn)
plot(cos2.nn)
install.packages('neuralnet')
install.packages("neuralnet")
install.packages("neuralnet")
install.packages("neuralnet")
library(neuralnet)
library(dummy)
prod = read.csv("productivityREG.csv", header=TRUE)
pwd
prod = read.csv("productivityREG.csv", header=TRUE)
# Importing data
wine = read.csv("productivityREG.csv", header=TRUE)
prod = read.csv("productivityREG.csv", header=TRUE)
getwd()
setwd("C:\chj\Rstudy\datamining")
setwd("C:\\chj\\Rstudy\\datamining")
prod = read.csv("productivityREG.csv", header=TRUE)
prod$quarter = factor(prod$quarter)
prod$department = factor(prod$department)
prod$day = factor(prod$day)
prod$team = factor(prod$team)
# Create dummy variables
dvar = c(1:4)
prod2 = dummy(x=prod[,dvar])
prod2 = prod2[,-c(5,7,13,25)] # 모형비교를 위한 데이터세트 생성(범주수-1)
library(dummy)
install.packages("dummy")
library(dummy)
prod2 = dummy(x=prod[,dvar])
prod2 = prod2[,-c(5,7,13,25)] # 모형비교를 위한 데이터세트 생성(범주수-1)
# 이를 삭제하면 범주 수만큼의 가변수 생성
prod2 = cbind(prod[,-dvar], prod2)
for(i in 1: ncol(prod2)) if(!is.numeric(prod2[,i])) prod2[,i] = as.numeric(prod2[,i])
# Standardization
max1 = apply(prod2, 2, max)
min1 = apply(prod2, 2, min)
sdat = scale(prod2, center = min1, scale = max1 - min1)
sdat = as.data.frame(sdat)
pn = names(sdat)
f = as.formula(paste("productivity~", paste(pn[!pn %in% "productivity"], collapse = " + ")))
set.seed(1234)
fit.nn = neuralnet(f, data = sdat, hidden=c(3,1), linear.output=T)
plot(fit.nn)
# Prediction
pred.nn = predict(fit.nn, sdat)
pred.nn = pred.nn * (max1[7]-min1[7])+min1[7]
# Mean Squared Error(MSE)
mean((prod2$productivity-pred.nn)^2)
# Scatter plot (Observed vs. Fitted)
plot(prod2$productivity, pred.nn, xlab="Observed Values", ylab="Fitted Values")
abline(0,1)
library(neralnet)
install.packages('neuralnet')
install.packages('neuralnet')
install.packages("neuralnet")
install.packages("neuralnet")
library(neralnet)
library(neuralnet)
setwd("C:\\chj\\Rstudy\\datamining")
wine = read.csv("winequalityCLASS.csv", header=TRUE)
# Set a critical value
cutoff = 0.5
# Standardization
max1 = apply(wine, 2, max)
min1 = apply(wine, 2, min)
gdat = scale(wine, center = min1, scale = max1 - min1)
gadt = as.data.frame(gdat)
gn = names(gdat)
f = as.formula(paste("quality~", paste(gn[!gn %in% "quality"], collapse = " + ")))
f = as.formula(paste("quality~.", paste(gn[!gn %in% "quality"], collapse = " + ")))
set.seeed(1234)
fit.nn = neuarlnet(f, data=gdat, hidden=c(2,1), linear.output=F)
fit.nn = neuralnet(f, data=gdat, hidden=c(2,1), linear.output=F)
plot(fit.nn)
# Prediction
p.nn = predict(fit.nn, gdat)
yhat.nn = ifelse(p.nn > cutoff, 1, 0)
# Confusion matrix
tab = table(gdat$quality, yhat.nn, dnn=c("Observed", "Predicted"))
print(tab)
sum(diag(tab))/nrow(gdat) #accuracy
tab[2,2]/sum(tab[2,])     #sensitivity
tab[1,1]/sum(tab[1,])     #sepcificity
# Confusion matrix
tab = table(gdat$quality, yhat.nn, dnn=c("Observed", "Predicted"))
print(tab)
